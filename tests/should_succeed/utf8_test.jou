import "stdlib/assert.jou"
import "stdlib/io.jou"
import "stdlib/random.jou"
import "stdlib/str.jou"
import "stdlib/utf8.jou"


def test_char_count() -> None:
    puts("char count")  # Output: char count
    printf("%zd\n", utf8_char_count("foo"))  # Output: 3
    printf("%zd\n", utf8_char_count("Ã¶rkkiðŸ˜€") as int)  # Output: 6
    printf("%zd\n", utf8_char_count("") as int)  # Output: 0


def test_successful_decode() -> None:
    puts("success decode")  # Output: success decode
    string = "Ã¶rkkiâ‚¬ðŸ˜€"
    s = string
    printf("%d\n", utf8_decode_char(&s))  # Output: 246
    printf("%d\n", utf8_decode_char(&s))  # Output: 114
    printf("%d\n", utf8_decode_char(&s))  # Output: 107
    printf("%d\n", utf8_decode_char(&s))  # Output: 107
    printf("%d\n", utf8_decode_char(&s))  # Output: 105
    printf("%d\n", utf8_decode_char(&s))  # Output: 8364
    printf("%d\n", utf8_decode_char(&s))  # Output: 128512
    printf("%d\n", utf8_decode_char(&s))  # Output: 0
    printf("%d\n", utf8_decode_char(&s))  # Output: 0
    printf("%d\n", utf8_decode_char(&s))  # Output: 0
    assert s == &string[strlen(string)]


def check_fail(s: byte*) -> None:
    ptr = s
    printf("should fail --> %d\n", utf8_decode_char(&ptr))
    assert ptr == s


def test_repeated_start_byte() -> None:
    puts("repeated start byte")  # Output: repeated start byte
    s: byte[10] = "mÃ¶rkÃ¶"
    strcpy(&s[2], "Ã¶")

    ptr = &s[0]
    printf("m = %d\n", utf8_decode_char(&ptr))  # Output: m = 109
    assert ptr == &s[1]
    check_fail(ptr)  # Output: should fail --> -1


def test_truncated() -> None:
    puts("truncated")  # Output: truncated
    s: byte[10] = "mÃ¶rkÃ¶"
    s[2] = '\0'

    ptr = &s[0]
    printf("m = %d\n", utf8_decode_char(&ptr))  # Output: m = 109
    assert ptr == &s[1]
    check_fail(ptr)  # Output: should fail --> -1


def test_missing_start() -> None:
    puts("missing start")  # Output: missing start
    s = "mÃ¶rkÃ¶"
    # Go to middle of Ã¶ character
    check_fail(&s[2])  # Output: should fail --> -1


def test_overlong_encoding() -> None:
    puts("overlong")  # Output: overlong

    # Let's make an overlong encoding of the euro sign â‚¬. It is also known as
    # U+20AC. Converting from hexadecimal to binary (e.g. A = 1010), the bits
    # of â‚¬ are:
    #
    #   U+20AC = 0010 0000 1010 1100
    #
    # The correct way to assemble these into UTF-8 is to use 3 bytes:
    #
    #   U+20AC = 0010 000010 101100
    assert "â‚¬"[0] == 0b1110_0010  # start byte for 3-byte character
    assert "â‚¬"[1] == 0b10_000010  # first continuation byte
    assert "â‚¬"[2] == 0b10_101100  # second continuation byte
    assert "â‚¬"[3] == '\0'

    # The wrong (overlong) way to assemble the bits into UTF-8 is to use 4 bytes:
    #
    #   U+20AC = 000 000010 000010 101100
    bad_euro_sign: byte[4] = [0b11110_000, 0b10_000010, 0b10_000010, 0b10_101100]
    check_fail(bad_euro_sign)  # Output: should fail --> -1

    # 4-byte sequences are for e.g. ðŸ˜€ (U+1F600)
    #
    #   U+1F600 = 0001 1111 0110 0000 0000
    #           = 000 011111 011000 000000
    smiley: byte[4] = [0b11110_000, 0b10_011111, 0b10_011000, 0b10_000000]
    ptr = &smiley[0]
    printf("smiley = %d\n", utf8_decode_char(&ptr))  # Output: smiley = 128512
    assert ptr == &smiley[4]


def test_4byte_sequence_that_decodes_to_large_value() -> None:
    puts("4byte to large")  # Output: 4byte to large

    # Wikipedia says that UTF-8 decoders should be prepared to handle 4-byte
    # sequences that decode to greater than U+10FFFF. Let's construct a couple.
    #
    #   U+110000    = 1 0001 0000 0000 0000 0000
    #               = 100 010000 000000 000000
    bad_4byte_sequence: byte[4] = [0b11110_100, 0b10_010000, 0b10_000000, 0b10_000000]
    check_fail(bad_4byte_sequence)  # Output: should fail --> -1

    #   U+110123    = 1 0001 0000 0001 0010 0011
    #               = 100 010000 000100 100011
    bad_4byte_sequence = [0b11110_100, 0b10_010000, 0b10_000100, 0b10_100011]
    check_fail(bad_4byte_sequence)  # Output: should fail --> -1


def test_surrogates() -> None:
    puts("surrogates")  # Output: surrogates

    # Let's make UTF-8 sequences that decode to U+D800...U+DFFF. They should be banned.
    #
    #   U+D800  = 1101 1000 0000 0000
    #           = 1101 100000 000000
    surrogate1: byte[3] = [0b1110_1101, 0b10_100000, 0b10_000000]

    #   U+DAAA  = 1101 1010 1010 1010
    #           = 1101 101010 101010
    surrogate2: byte[3] = [0b1110_1101, 0b10_101010, 0b10_101010]

    #   U+DFFF  = 1101 1111 1111 1111
    #           = 1101 111111 111111
    surrogate3: byte[3] = [0b1110_1101, 0b10_111111, 0b10_111111]

    check_fail(surrogate1)  # Output: should fail --> -1
    check_fail(surrogate2)  # Output: should fail --> -1
    check_fail(surrogate3)  # Output: should fail --> -1


def test_decoding_random_data() -> None:
    num_iters = 10000
    valid_count = 0

    for iter = 0; iter < num_iters; iter++:
        string = [rand() as byte, rand() as byte, rand() as byte, rand() as byte, '\0']
        ptr = &string[0]

        while utf8_decode_char(&ptr) > 0:
            pass
        if *ptr == '\0':
            # We got to end of string, it is valid UTF-8
            valid_count++

    # It is very consistently valid about 10% of the time. I compared with Python.
    #printf("%f\n", valid_count / (num_iters as double))
    if 0.07*num_iters <= valid_count and valid_count <= 0.12*num_iters:
        printf("random data check ok\n")  # Output: random data check ok
    else:
        printf("valid_count=%d num_iters=%d\n", valid_count, num_iters)


def test_encode_char() -> None:
    puts("encode char")  # Output: encode char

    s: byte[5]

    s = utf8_encode_char('A')
    puts(s)  # Output: A

    # Test various non-ASCII characters. Do not print them because any Windows
    # IO weirdness I may run into is not a bug in the UTF-8 module.
    s = utf8_encode_char(246)  # Ã¶
    printf("%d,%d,%d,%d,%d\n", s[0], s[1], s[2], s[3], s[4])  # Output: 195,182,0,0,0
    s = utf8_encode_char(0x20AC)  # â‚¬
    printf("%d,%d,%d,%d,%d\n", s[0], s[1], s[2], s[3], s[4])  # Output: 226,130,172,0,0
    s = utf8_encode_char(0x1F600)  # ðŸ˜€
    printf("%d,%d,%d,%d,%d\n", s[0], s[1], s[2], s[3], s[4])  # Output: 240,159,152,128,0
    s = utf8_encode_char(0xD800)  # surrogate --> error
    printf("%d,%d,%d,%d,%d\n", s[0], s[1], s[2], s[3], s[4])  # Output: 0,0,0,0,0
    s = utf8_encode_char(0x110000)  # too large --> error
    printf("%d,%d,%d,%d,%d\n", s[0], s[1], s[2], s[3], s[4])  # Output: 0,0,0,0,0
    s = utf8_encode_char(0)
    printf("%d,%d,%d,%d,%d\n", s[0], s[1], s[2], s[3], s[4])  # Output: 0,0,0,0,0


def main() -> int:
    test_char_count()
    test_successful_decode()
    test_repeated_start_byte()
    test_truncated()
    test_missing_start()
    test_overlong_encoding()
    test_4byte_sequence_that_decodes_to_large_value()
    test_surrogates()
    test_decoding_random_data()
    test_encode_char()
    return 0
