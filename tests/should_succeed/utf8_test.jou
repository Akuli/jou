import "stdlib/io.jou"
import "stdlib/rand.jou"
import "stdlib/str.jou"
import "stdlib/utf8.jou"


def test_char_count() -> None:
    puts("char count")  # Output: char count
    printf("%d\n", utf8_char_count("foo"))  # Output: 3
    printf("%d\n", utf8_char_count("Ã¶rkkiğŸ˜€") as int)  # Output: 6
    printf("%d\n", utf8_char_count("") as int)  # Output: 0


def test_successful_decode() -> None:
    puts("success decode")  # Output: success decode
    string = "Ã¶rkkiâ‚¬ğŸ˜€"
    s = string
    printf("%u\n", utf8_decode_char(&s))  # Output: 246
    printf("%u\n", utf8_decode_char(&s))  # Output: 114
    printf("%u\n", utf8_decode_char(&s))  # Output: 107
    printf("%u\n", utf8_decode_char(&s))  # Output: 107
    printf("%u\n", utf8_decode_char(&s))  # Output: 105
    printf("%u\n", utf8_decode_char(&s))  # Output: 8364
    printf("%u\n", utf8_decode_char(&s))  # Output: 128512
    printf("%u\n", utf8_decode_char(&s))  # Output: 0
    printf("%u\n", utf8_decode_char(&s))  # Output: 0
    printf("%u\n", utf8_decode_char(&s))  # Output: 0
    assert s == &string[strlen(string)]


def check_fail(s: byte*) -> None:
    ptr = s
    printf("should fail --> %u\n", utf8_decode_char(&ptr))
    assert ptr == s


def test_repeated_start_byte() -> None:
    puts("repeated start byte")  # Output: repeated start byte
    s: byte[10] = "mÃ¶rkÃ¶"
    strcpy(&s[2], "Ã¶")

    ptr = &s[0]
    printf("m = %u\n", utf8_decode_char(&ptr))  # Output: m = 109
    assert ptr == &s[1]
    check_fail(ptr)  # Output: should fail --> 0


def test_truncated() -> None:
    puts("truncated")  # Output: truncated
    s: byte[10] = "mÃ¶rkÃ¶"
    s[2] = '\0'

    ptr = &s[0]
    printf("m = %u\n", utf8_decode_char(&ptr))  # Output: m = 109
    assert ptr == &s[1]
    check_fail(ptr)  # Output: should fail --> 0


def test_missing_start() -> None:
    puts("missing start")  # Output: missing start
    s = "mÃ¶rkÃ¶"
    # Go to middle of Ã¶ character
    check_fail(&s[2])  # Output: should fail --> 0


def test_overlong_encoding() -> None:
    puts("overlong")  # Output: overlong

    # Let's make an overlong encoding of the euro sign â‚¬. It is also known as
    # U+20AC. Converting from hexadecimal to binary (e.g. A = 1010), the bits
    # of â‚¬ are:
    #
    #   U+20AC = 0010 0000 1010 1100
    #
    # The correct way to assemble these into UTF-8 is to use 3 bytes:
    #
    #   U+20AC = 0010 000010 101100
    assert "â‚¬"[0] == 0b1110_0010  # start byte for 3-byte character
    assert "â‚¬"[1] == 0b10_000010  # first continuation byte
    assert "â‚¬"[2] == 0b10_101100  # second continuation byte
    assert "â‚¬"[3] == '\0'

    # The wrong (overlong) way to assemble the bits into UTF-8 is to use 4 bytes:
    #
    #   U+20AC = 000 000010 000010 101100
    bad_euro_sign: byte[4] = [0b11110_000, 0b10_000010, 0b10_000010, 0b10_101100]
    check_fail(bad_euro_sign)  # Output: should fail --> 0

    # 4-byte sequences are for e.g. ğŸ˜€ (U+1F600)
    #
    #   U+1F600 = 0001 1111 0110 0000 0000
    #           = 000 011111 011000 000000
    smiley: byte[4] = [0b11110_000, 0b10_011111, 0b10_011000, 0b10_000000]
    ptr = &smiley[0]
    printf("smiley = %u\n", utf8_decode_char(&ptr))  # Output: smiley = 128512
    assert ptr == &smiley[4]


def test_4byte_sequence_that_decodes_to_large_value() -> None:
    puts("4byte to large")  # Output: 4byte to large

    # Wikipedia says that UTF-8 decoders should be prepared to handle 4-byte
    # sequences that decode to greater than U+10FFFF. Let's construct a couple.
    #
    #   U+110000    = 1 0001 0000 0000 0000 0000
    #               = 100 010000 000000 000000
    bad_4byte_sequence: byte[4] = [0b11110_100, 0b10_010000, 0b10_000000, 0b10_000000]
    check_fail(bad_4byte_sequence)  # Output: should fail --> 0

    #   U+110123    = 1 0001 0000 0001 0010 0011
    #               = 100 010000 000100 100011
    bad_4byte_sequence = [0b11110_100, 0b10_010000, 0b10_000100, 0b10_100011]
    check_fail(bad_4byte_sequence)  # Output: should fail --> 0


def test_surrogates() -> None:
    puts("surrogates")  # Output: surrogates

    # Let's make UTF-8 sequences that decode to U+D800...U+DFFF. They should be banned.
    #
    #   U+D800  = 1101 1000 0000 0000
    #           = 1101 100000 000000
    surrogate1: byte[3] = [0b1110_1101, 0b10_100000, 0b10_000000]

    #   U+DAAA  = 1101 1010 1010 1010
    #           = 1101 101010 101010
    surrogate2: byte[3] = [0b1110_1101, 0b10_101010, 0b10_101010]

    #   U+DFFF  = 1101 1111 1111 1111
    #           = 1101 111111 111111
    surrogate3: byte[3] = [0b1110_1101, 0b10_111111, 0b10_111111]

    check_fail(surrogate1)  # Output: should fail --> 0
    check_fail(surrogate2)  # Output: should fail --> 0
    check_fail(surrogate3)  # Output: should fail --> 0


def test_decoding_random_data() -> None:
    num_iters = 10000
    valid_count = 0

    for iter = 0; iter < num_iters; iter++:
        string = [rand() as byte, rand() as byte, rand() as byte, rand() as byte, '\0']
        ptr = &string[0]

        while utf8_decode_char(&ptr) != 0:
            pass
        if *ptr == '\0':
            # We got to end of string, it is valid UTF-8
            valid_count++

    # It is very consistently valid about 10% of the time. I compared with Python.
    #printf("%f\n", valid_count / (num_iters as double))
    if 0.08*num_iters <= valid_count and valid_count <= 0.12*num_iters:
        printf("random data check ok\n")  # Output: random data check ok


def main() -> int:
    test_char_count()
    test_successful_decode()
    test_repeated_start_byte()
    test_truncated()
    test_missing_start()
    test_overlong_encoding()
    test_4byte_sequence_that_decodes_to_large_value()
    test_surrogates()
    test_decoding_random_data()
    return 0
