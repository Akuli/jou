import "stdlib/io.jou"
import "stdlib/str.jou"
import "stdlib/mem.jou"
import "./errors_and_warnings.jou"
import "./token.jou"

def is_identifier_or_number_byte(b: byte) -> bool:
    return (
        ('A' <= b and b <= 'Z')
        or ('a' <= b and b <= 'z')
        or ('0' <= b and b <= '9')
        or b == '_'
    )

def is_operator_byte(c: byte) -> bool:
    return c != '\0' and strchr("=<>!.,()[]{};:+-*/&%|", c) != NULL

def is_keyword(word: byte*) -> bool:
    # This keyword list is in 3 places. Please keep them in sync:
    #   - the Jou compiler written in C
    #   - self-hosted compiler
    #   - syntax documentation
    keywords = [
        "import", "def", "declare", "class", "union", "enum", "global",
        "return", "if", "elif", "else", "while", "for", "break", "continue", "pass", 
        "True", "False", "NULL", "self",
        "and", "or", "not", "as", "sizeof", "assert",
        "void", "noreturn",
        "bool", "byte", "short", "int", "long", "float", "double",
    ]

    for i = 0; i < sizeof keywords / sizeof keywords[0]; i++:
        if strcmp(keywords[i], word) == 0:
            return True
    return False

def hexdigit_value(c: byte) -> int:
    if 'A' <= c and c <= 'F':
        return 10 + (c - 'A')
    if 'a' <= c and c <= 'f':
        return 10 + (c - 'a')
    if '0' <= c and c <= '9':
        return c - '0'
    return -1

def parse_integer(string: byte*, location: Location, nbits: int) -> long:
    if starts_with(string, "0b"):
        base = 2
        digits = &string[2]
        valid_digits = "01"
    elif starts_with(string, "0o"):
        base = 8
        digits = &string[2]
        valid_digits = "01234567"
    elif starts_with(string, "0x"):
        base = 16
        digits = &string[2]
        valid_digits = "0123456789ABCDEFabcdef"
    elif starts_with(string, "0") and strlen(string) >= 2:
        # wrong syntax like 0777
        fail(location, "unnecessary zero at start of number")
    else:
        # default decimal number
        base = 10
        digits = string
        valid_digits = "0123456789"

    if strlen(digits) == 0 or strspn(digits, valid_digits) != strlen(digits):
        message = malloc(strlen(string) + 100)
        sprintf(message, "invalid number or variable name \"%s\"", string)
        fail(location, message)

    # We can't use strtoll() or similar, because there's not yet a way to check errno.
    # We would need it to check for overflow.
    result = 0L
    overflow = False

    for i = 0; i < strlen(digits); i++:
        # Overflow isn't UB in Jou
        if (result * base) / base != result:
            overflow = True
            break
        result *= base

        if result + hexdigit_value(digits[i]) < 0:
            overflow = True
            break
        result += hexdigit_value(digits[i])

    assert nbits == 16 or nbits == 32 or nbits == 64
    if nbits == 32 and (result as int) != result:
        overflow = True
        
    if nbits == 16 and (result as short) != result:
        overflow = True

    if overflow:
        message = malloc(100)
        sprintf(message, "value does not fit in a signed %d-bit integer", nbits)
        fail(location, message)

    return result

# Does a string contain multiple occurrences of the given byte?
def has_multiple(s: byte*, b: byte) -> bool:
    return strchr(s, b) != strrchr(s, b)

def is_valid_double(str: byte*) -> bool:
    if strspn(str, "0123456789.-e") < strlen(str):
        return False
    if has_multiple(str, '.') or has_multiple(str, '-') or has_multiple(str, 'e'):
        return False

    dot = strchr(str, '.')
    minus = strchr(str, '-')
    e = strchr(str, 'e')

    return (
        # 123.456
        e == NULL and minus == NULL and dot != NULL
    ) or (
        # 1e-4
        e != NULL and e[1] != '\0' and (dot == NULL or dot < e) and  (minus == NULL or (&e[1] == minus and e[2] != '\0'))
    )

def is_valid_float(str: byte[100]) -> bool:
    n = strlen(str)
    if n == 0 or (str[n-1] != 'F' and str[n-1] != 'f'):
        return False
    str[n-1] = '\0'
    return is_valid_double(str) or strspn(str, "0123456789") == strlen(str)


def flip_paren(c: byte) -> byte:
    if c == '(':
        return ')'
    if c == ')':
        return '('
    if c == '[':
        return ']'
    if c == ']':
        return '['
    if c == '{':
        return '}'
    if c == '}':
        return '{'
    assert False


class Tokenizer:
    f: FILE*
    location: Location
    pushback: byte*
    pushback_len: int  # TODO: dynamic array
    # Parens array isn't dynamic, so that you can't segfault
    # the compiler by feeding it lots of nested parentheses,
    # which would make it recurse too deep.
    open_parens: Token[50]
    open_parens_len: int

    def read_byte(self) -> byte:
        EOF = -1  # FIXME

        c: byte
        if self->pushback_len > 0:
            c = self->pushback[--self->pushback_len]
        else:
            temp = fgetc(self->f)
            if temp == '\r':
                # On Windows, \r just before \n is ignored.
                temp = fgetc(self->f)
                if temp != EOF and temp != '\n':
                    # TODO: test this, if possible?
                    fail(self->location, "source file contains a CR byte ('\\r') that isn't a part of a CRLF line ending")

            if temp == EOF:
                if ferror(self->f) != 0:
                    # TODO: include errno in the error message
                    fail(self->location, "cannot read file")
                # Use the zero byte to denote end of file.
                c = '\0'
            elif temp == '\0':
                # TODO: test this
                fail(self->location, "source file contains a zero byte")
            else:
                c = temp as byte

        if c == '\n':
            self->location.lineno++
        return c

    def unread_byte(self, b: byte) -> void:
        if b == '\0':
            return

        assert b != '\r'
        self->pushback = realloc(self->pushback, self->pushback_len + 1)
        self->pushback[self->pushback_len++] = b
        if b == '\n':
            self->location.lineno--

    def read_identifier_or_number(self, first_byte: byte) -> byte[100]:
        dest: byte[100]
        memset(&dest, 0, sizeof dest)
        destlen = 0

        assert is_identifier_or_number_byte(first_byte)
        dest[destlen++] = first_byte
        is_number = '0' <= first_byte and first_byte <= '9'

        while True:
            b = self->read_byte()
            if (
                is_identifier_or_number_byte(b)
                or (is_number and (b == '.' or (b == '-' and dest[destlen-1] == 'e')))
            ):
                if destlen == sizeof dest - 1:
                    if is_number:
                        template = "number is too long: %.20s..."
                    else:
                        template = "name is too long: %.20s..."
                    message: byte[100]
                    sprintf(message, template, dest)
                    fail(self->location, message)
                dest[destlen++] = b
            else:
                self->unread_byte(b)
                return dest

    def consume_rest_of_line(self) -> void:
        while True:
            c = self->read_byte()
            if c == '\0' or c == '\n':
                self->unread_byte(c)
                break

    # Returns the indentation level for the next line
    def read_newline_token(self) -> int:
        level = 0
        while True:
            c = self->read_byte()
            if c == '\0':
                # End of file. Do not validate that indentation is a
                # multiple of 4 spaces. Add a trailing newline implicitly
                # if needed.
                #
                # TODO: test this
                return 0
            elif c == '\n':
                level = 0
            elif c == '#':
                self->consume_rest_of_line()
            elif c == ' ':
                level++
            else:
                self->unread_byte(c)
                return level

    def read_hex_escape_byte(self) -> byte:
        n1 = hexdigit_value(self->read_byte())
        n2 = hexdigit_value(self->read_byte())
        if n1 == -1 or n2 == -1:
            fail(self->location, "\\x must be followed by two hexadecimal digits (0-9, A-F) to specify a byte")
        return (n1*16 + n2) as byte

    # Assumes the initial ' has been read.
    def read_byte_literal(self) -> byte:
        c = self->read_byte()
        if c == '\'':
            fail(self->location, "a byte literal cannot be empty, maybe use double quotes to instead make a string?")
        if c == '\0' or c == '\n':
            if c == '\n':
                self->location.lineno--
            fail(self->location, "missing ' to end the byte literal")

        if c == '\\':
            after_backslash = self->read_byte()
            if after_backslash == '\0' or after_backslash == '\n':
                fail(self->location, "missing ' to end the byte literal")
            elif after_backslash == 'n':
                c = '\n'
            elif after_backslash == 'r':
                c = '\r'
            elif after_backslash == 't':
                c = '\t'
            elif after_backslash == '\\':
                c = '\\'
            elif after_backslash == '\'':
                c = '\''
            elif after_backslash == '"':
                fail(self->location, "double quotes shouldn't be escaped in byte literals")
            elif after_backslash == '0':
                c = '\0'
            elif after_backslash == 'x':
                c = self->read_hex_escape_byte()
            elif after_backslash < 0x80 and isprint(after_backslash) != 0:
                message: byte* = malloc(100)
                sprintf(message, "unknown escape: '\\%c'", after_backslash)
                fail(self->location, message)
            else:
                fail(self->location, "unknown '\\' escape")

        end = self->read_byte()
        if end != '\'':
            # If there's another single quote later on the same line, suggest using double quotes.
            location = self->location
            while True:
                c = self->read_byte()
                if c == '\0' or c == '\n':
                    break
                if c == '\'':
                    fail(location, "single quotes are for a single character, maybe use double quotes to instead make a string?")
            fail(location, "missing ' to end the byte literal")

        return c

    # Assumes the initial " has been read.
    def read_string(self) -> byte*:
        result: byte* = NULL
        len = 0

        while True:
            c = self->read_byte()
            if c == '"':
                break
            elif c == '\n' or c == '\0':
                if c == '\n':
                    self->location.lineno--
                fail(self->location, "missing \" to end the string")
            elif c == '\\':
                # \n means newline, for example
                after_backslash = self->read_byte()
                if after_backslash == '\0':
                    fail(self->location, "missing \" to end the string")
                elif after_backslash == 'n':
                    result = realloc(result, len+1)
                    result[len++] = '\n'
                elif after_backslash == 'r':
                    result = realloc(result, len+1)
                    result[len++] = '\r'
                elif after_backslash == 't':
                    result = realloc(result, len+1)
                    result[len++] = '\t'
                elif after_backslash == '\\' or after_backslash == '"':
                    result = realloc(result, len+1)
                    result[len++] = after_backslash
                elif after_backslash == '\'':
                    fail(self->location, "single quotes shouldn't be escaped in strings")
                elif after_backslash == '0':
                    fail(self->location, "strings cannot contain zero bytes (\\0), because that is the special end marker byte")
                elif after_backslash == 'x':
                    b = self->read_hex_escape_byte()
                    if b == '\0':
                        fail(self->location, "strings cannot contain zero bytes (\\x00), because that is the special end marker byte")
                    result = realloc(result, len+1)
                    result[len++] = b
                elif after_backslash == '\n':
                    # \ at end of line, string continues on next line
                    pass
                else:
                    if after_backslash < 0x80 and isprint(after_backslash) != 0:
                        message: byte* = malloc(100)
                        sprintf(message, "unknown escape: '\\%c'", after_backslash)
                        fail(self->location, message)
                    else:
                        fail(self->location, "unknown '\\' escape")
            else:
                result = realloc(result, len+1)
                result[len++] = c

        result = realloc(result, len+1)
        result[len] = '\0'
        return result

    def read_operator(self) -> byte[100]:
        operators = [
            # This list of operators is in 3 places. Please keep them in sync:
            #   - the Jou compiler written in C
            #   - self-hosted compiler
            #   - syntax documentation
            #
            # Longer operators are first, so that '==' does not tokenize as '=' '='
            "...", "===", "!==",
            "==", "!=", "->", "<=", ">=", "++", "--", "+=", "-=", "*=", "/=", "%=", "::", "&&", "||",
            ".", ",", ":", ";", "=", "(", ")", "{", "}", "[", "]", "&", "%", "*", "/", "+", "-", "<", ">", "!",
        ]

        operator: byte[100]
        memset(&operator, 0, sizeof operator)

        # Read as many operator characters as we may need.
        while strlen(operator) < 3:
            c = self->read_byte()
            if not is_operator_byte(c):
                self->unread_byte(c)
                break
            operator[strlen(operator)] = c

        for i = 0; i < sizeof operators / sizeof operators[0]; i++:
            if starts_with(operator, operators[i]):
                # Unread the bytes we didn't use.
                while strlen(operator) > strlen(operators[i]):
                    last = &operator[strlen(operator) - 1]
                    self->unread_byte(*last)
                    *last = '\0'

                # These operators are here only to give a better error message when you
                # accidentally use syntax of another programming language.
                if strcmp(operator, "===") == 0:
                    fail(self->location, "use '==' instead of '==='")
                if strcmp(operator, "!==") == 0:
                    fail(self->location, "use '!=' instead of '!=='")
                if strcmp(operator, "&&") == 0:
                    fail(self->location, "use 'and' instead of '&&'")
                if strcmp(operator, "||") == 0:
                    fail(self->location, "use 'or' instead of '||'")
                if strcmp(operator, "!") == 0:
                    fail(self->location, "use 'not' instead of '!'")

                return operator

        message: byte[100]
        sprintf(message, "there is no '%s' operator", operator)
        fail(self->location, message)

    def handle_parentheses(self, token: Token*) -> void:
        if token->kind == TokenKind::EndOfFile and self->open_parens_len > 0:
            open_token = self->open_parens[0]
            actual_open = open_token.short_string[0]
            expected_close = flip_paren(actual_open)

            message = malloc(100)
            sprintf(message, "'%c' without a matching '%c'", actual_open, expected_close)
            fail(open_token.location, message)

        if token->is_open_paren():
            if self->open_parens_len == sizeof self->open_parens / sizeof self->open_parens[0]:
                fail(token->location, "too many nested parentheses")
            self->open_parens[self->open_parens_len++] = *token

        if token->is_close_paren():
            actual_close = token->short_string[0]
            expected_open = flip_paren(actual_close)
            if self->open_parens_len == 0 or self->open_parens[--self->open_parens_len].short_string[0] != expected_open:
                message = malloc(100)
                sprintf(message, "'%c' without a matching '%c'", actual_close, expected_open)
                fail(token->location, message)

    def read_token(self) -> Token:
        while True:
            token = Token{location = self->location}
            b = self->read_byte()

            if b == ' ':
                continue
            if b == '#':
                self->consume_rest_of_line()
                continue

            if b == '\n':
                if self->open_parens_len > 0:
                    continue
                token.kind = TokenKind::Newline
                token.indentation_level = self->read_newline_token()
            elif b == '"':
                token.kind = TokenKind::String
                token.long_string = self->read_string()
            elif b == '\'':
                token.kind = TokenKind::Byte
                token.byte_value = self->read_byte_literal()
            elif is_identifier_or_number_byte(b):
                token.short_string = self->read_identifier_or_number(b)
                if is_keyword(token.short_string):
                    token.kind = TokenKind::Keyword
                elif '0' <= token.short_string[0] and token.short_string[0] <= '9':
                    if is_valid_double(token.short_string):
                        token.kind = TokenKind::Double
                    elif is_valid_float(token.short_string):
                        token.short_string[strlen(token.short_string) - 1] = '\0'  # delete trailing 'f' or 'F'
                        token.kind = TokenKind::Float
                    elif token.short_string[strlen(token.short_string) - 1] == 'L':
                        token.short_string[strlen(token.short_string) - 1] = '\0'
                        token.kind = TokenKind::Long
                        token.long_value = parse_integer(token.short_string, token.location, 64)
                    elif token.short_string[strlen(token.short_string) - 1] == 'S':
                        token.short_string[strlen(token.short_string) - 1] = '\0'
                        token.kind = TokenKind::Short
                        token.short_value = parse_integer(token.short_string, token.location, 16) as short
                    else:
                        token.kind = TokenKind::Int
                        token.int_value = parse_integer(token.short_string, token.location, 32) as int
                else:
                    token.kind = TokenKind::Name
            elif is_operator_byte(b):
                self->unread_byte(b)
                token.kind = TokenKind::Operator
                token.short_string = self->read_operator()
            elif b == '\t':
                fail(self->location, "Jou files cannot contain tab characters (use 4 spaces for indentation)")
            elif b == '\0':
                token.kind = TokenKind::EndOfFile
            else:
                message: byte[100]
                if b < 0x80 and isprint(b) != 0:
                    sprintf(message, "unexpected byte '%c' (%#02x)", b, b)
                else:
                    sprintf(message, "unexpected byte %#02x", b)
                fail(self->location, message)

            self->handle_parentheses(&token)
            return token


def tokenize_without_indent_dedent_tokens(file: FILE*, path: byte*) -> Token*:
    tokenizer = Tokenizer{
        location = Location{path = path},
        f = file,
    }

    # Add a fake newline to the beginning. It does a few things:
    #  * Less special-casing: blank lines in the beginning of the file can
    #    cause there to be a newline token anyway.
    #  * It is easier to detect an unexpected indentation in the beginning
    #    of the file, as it becomes just like any other indentation.
    #  * Line numbers start at 1.
    tokenizer.pushback = malloc(1)
    tokenizer.pushback[0] = '\n'
    tokenizer.pushback_len = 1

    tokens: Token* = NULL
    len = 0
    while len == 0 or tokens[len-1].kind != TokenKind::EndOfFile:
        tokens = realloc(tokens, sizeof(tokens[0]) * (len+1))
        tokens[len++] = tokenizer.read_token()

    free(tokenizer.pushback)
    return tokens


# Creates a new array of tokens with indent/dedent tokens added after
# newline tokens that change the indentation level.
def handle_indentations(raw_tokens: Token*) -> Token*:
    tokens: Token* = NULL
    ntokens = 0
    level = 0

    for t = raw_tokens; True; t++:
        if t->kind == TokenKind::EndOfFile:
            # Add an extra newline token at end of file and the dedents after it.
            # This makes it similar to how other newline and dedent tokens work:
            # the dedents always come after a newline token.
            tokens = realloc(tokens, sizeof tokens[0] * (ntokens + level/4 + 1))
            while level != 0:
                tokens[ntokens++] = Token{location = t->location, kind = TokenKind::Dedent}
                level -= 4
            tokens[ntokens++] = *t
            break

        tokens = realloc(tokens, sizeof tokens[0] * (ntokens+1))
        tokens[ntokens++] = *t

        if t->kind == TokenKind::Newline:
            after_newline = t->location
            after_newline.lineno++

            if t->indentation_level % 4 != 0:
                fail(after_newline, "indentation must be a multiple of 4 spaces")

            while level < t->indentation_level:
                tokens = realloc(tokens, sizeof tokens[0] * (ntokens+1))
                tokens[ntokens++] = Token{location = after_newline, kind = TokenKind::Indent}
                level += 4

            while level > t->indentation_level:
                tokens = realloc(tokens, sizeof tokens[0] * (ntokens+1))
                tokens[ntokens++] = Token{location = after_newline, kind = TokenKind::Dedent}
                level -= 4

    # Delete the newline token in the beginning.
    #
    # If the file has indentations after it, they are now represented by separate
    # indent tokens and parsing will fail. If the file doesn't have any blank/comment
    # lines in the beginning, it has a newline token anyway to avoid special casing.
    assert tokens[0].kind == TokenKind::Newline
    memmove(&tokens[0], &tokens[1], sizeof tokens[0] * (ntokens - 1))

    return tokens


def tokenize(path: byte*) -> Token*:
    file = fopen(path, "rb")
    if file == NULL:
        # TODO: test this
        # TODO: include errno in the message
        fail(Location{path=path}, "cannot open file")

    raw_tokens = tokenize_without_indent_dedent_tokens(file, path)
    better_tokens = handle_indentations(raw_tokens)
    free(raw_tokens)
    return better_tokens

def print_tokens(tokens: Token*) -> void:
    printf("===== Tokens for file \"%s\" =====\n", tokens->location.path)
    t = tokens
    current_lineno = -1

    while True:
        if t->location.lineno != current_lineno:
            current_lineno = t->location.lineno
            printf("\nLine %d:\n", current_lineno)

        printf("  ")
        t->print()

        if t->kind == TokenKind::EndOfFile:
            break
        t++

    printf("\n")
